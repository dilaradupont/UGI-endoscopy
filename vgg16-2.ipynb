{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3260, 586, 147, 230]\n",
      "[6321, 6993, 6524, 5348]\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "TRAINING_PATH = '/home/dilara/UGI-endoscopy/training-data'\n",
    "TESTING_PATH = '/home/dilara/UGI-endoscopy/testing-data'\n",
    "CLASSES = ['other2', 'pylorus', 'z-line', 'retroflex-stomach']\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Flatten \n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import skimage\n",
    "from skimage import io\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sbs\n",
    "from PIL import Image\n",
    "\n",
    "def get_paths(path):\n",
    "## setting the paths\n",
    "    all_paths = []\n",
    "    for landmark in CLASSES:\n",
    "        other_path = os.path.join(path, landmark, '*')\n",
    "        all_paths.append(sorted(glob.glob(other_path)))\n",
    "    return all_paths\n",
    "# all_paths = list(np.concatenate(all_paths).flat)\n",
    "\n",
    "def get_class_num(path):\n",
    "## finding the number of image per class\n",
    "    len_lis = []\n",
    "    for lis in path:\n",
    "        x = 0\n",
    "        for item in lis:\n",
    "            x+=1\n",
    "        len_lis.append(x)\n",
    "    print(len_lis)\n",
    "    return len_lis\n",
    "\n",
    "def create_labels(len_lis):\n",
    "    labels_lis = []\n",
    "    for i in range(4):\n",
    "        labels_lis.append([i] * len_lis[i])\n",
    "        all_labels = list(np.concatenate(labels_lis).flat)\n",
    "        all_labels = np.array(all_labels)\n",
    "    return all_labels\n",
    "\n",
    "all_paths_train = get_paths(TRAINING_PATH)\n",
    "all_paths_test = get_paths(TESTING_PATH)\n",
    "len_lis_train = get_class_num(all_paths_test)\n",
    "len_lis_test = get_class_num(all_paths_train)\n",
    "\n",
    "all_paths_train = list(np.concatenate(all_paths_train).flat)\n",
    "all_paths_test = list(np.concatenate(all_paths_test).flat)\n",
    "\n",
    "all_labels_train = create_labels(len_lis_train)\n",
    "all_labels_test = create_labels(len_lis_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmenting the Dataset\n",
    "# for path in all_paths:\n",
    "# \tfile_name = path[:len(path)-4]\n",
    "# \timage = cv2.imread(path)\n",
    "# \timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# \trows, cols, dim = image.shape\n",
    "\n",
    "# \t# flipping images upside down and leftright\n",
    "# \timage_fliplr = np.fliplr(image)\n",
    "# \timage_flipud = np.flipud(image)\n",
    "# \tplt.imsave(f'{file_name}_image_flipud.jpg', image_flipud)\n",
    "# \tplt.imsave(f'{file_name}_image_fliplr.jpg', image_fliplr)\n",
    "\n",
    "# \t# rotating image\n",
    "# \trotated_img = skimage.transform.rotate(image, 90)\n",
    "# \tplt.imsave(f'{file_name}_rotated_img.jpg', rotated_img)\n",
    "\n",
    "# \t# shear transform on x-axis\n",
    "# \tM = np.float32([[1, 0.7, 0],\n",
    "# \t\t\t\t\t[0, 1  , 0],\n",
    "# \t\t\t\t\t[0, 0  , 1]])             \n",
    "# \tsheared_img = cv2.warpPerspective(image,M,(int(cols*1.5),int(rows*1.5)))\n",
    "# \tplt.imsave(f'{file_name}_sheared_img.jpg', sheared_img)\n",
    "\n",
    "# \t## zoom out\n",
    "# \tM = np.float32([[1.5, 0  , 0],\n",
    "# \t\t\t\t\t[0,   1.5, 0],\n",
    "# \t\t\t\t\t[0,   0,   1]])\n",
    "# \tscaledin_img = cv2.warpPerspective(image,M,(cols,rows))\n",
    "# \tplt.imsave(f'{file_name}_scaledin_img.jpg', scaledin_img)\n",
    "\n",
    "# \tM = np.float32([[0.8, 0  , 0],\n",
    "# \t\t\t\t\t[0,   0.8, 0],\n",
    "# \t\t\t\t\t[0,   0,   1]])\n",
    "# \tscaledout_img = cv2.warpPerspective(image,M,(cols,rows))\n",
    "# \tplt.imsave(f'{file_name}_scaledout_img.jpg', scaledout_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Renaming the images\n",
    "# all_paths_test = []\n",
    "\n",
    "# for landmark in CLASSES:\n",
    "#     other_path = os.path.join(TESTING_PATH, landmark, '*')\n",
    "#     all_paths_test.append(sorted(glob.glob(other_path)))\n",
    "\n",
    "# all_paths_test = list(np.concatenate(all_paths_test).flat)\n",
    "\n",
    "# for path in all_paths_test:\n",
    "#     old = path\n",
    "#     new = f'{path[:len(path)-4]}_video5.jpg'\n",
    "#     os.rename(old, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/dilara/UGI-endoscopy/vgg16-2.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=7'>8</a>\u001b[0m         pix\u001b[39m.\u001b[39mappend(image_data)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pix\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=10'>11</a>\u001b[0m pix_train \u001b[39m=\u001b[39m get_pix(all_labels_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=11'>12</a>\u001b[0m pix_test \u001b[39m=\u001b[39m get_pix(all_labels_test)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=13'>14</a>\u001b[0m label_train \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mnp_utils\u001b[39m.\u001b[39mto_categorical(all_labels_train, num_classes\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n",
      "\u001b[1;32m/home/dilara/UGI-endoscopy/vgg16-2.ipynb Cell 4'\u001b[0m in \u001b[0;36mget_pix\u001b[0;34m(path_lis)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_pix\u001b[39m(path_lis):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m path_lis:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=4'>5</a>\u001b[0m         file_name \u001b[39m=\u001b[39m path\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=5'>6</a>\u001b[0m         image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(path)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.16.4.77/home/dilara/UGI-endoscopy/vgg16-2.ipynb#ch0000003vscode-remote?line=6'>7</a>\u001b[0m         image_data \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(image, IMAGE_SIZE, interpolation \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mINTER_AREA)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "pix = []\n",
    "\n",
    "def get_pix(path_lis):\n",
    "    for path in path_lis:\n",
    "        file_name = path.split('/')[-1]\n",
    "        image = cv2.imread(path)\n",
    "        image_data = cv2.resize(image, IMAGE_SIZE, interpolation = cv2.INTER_AREA)\n",
    "        pix.append(image_data)\n",
    "    return pix\n",
    "\n",
    "pix_train = get_pix(all_labels_train)\n",
    "pix_test = get_pix(all_labels_test)\n",
    "\n",
    "label_train = keras.utils.np_utils.to_categorical(all_labels_train, num_classes=4)\n",
    "label_test = keras.utils.np_utils.to_categorical(all_labels_test, num_classes=4)\n",
    "\n",
    "    # pix = np.array(pix)\n",
    "    # print(len(pix))\n",
    "    # pix_train, pix_val, label_train, label_val = train_test_split(pix, all_labels, train_size=0.75, random_state = 42)\n",
    "    # label_train = keras.utils.np_utils.to_categorical(label_train, num_classes=4)\n",
    "    # label_val = keras.utils.np_utils.to_categorical(label_val, num_classes=4)\n",
    "    # print(pix_train.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
