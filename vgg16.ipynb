{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-processing\n",
    "### 1.1. Imports and Setting the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "PATH = '/Users/dilaradupont/Desktop/UCL/Year 3/UGI-endoscopy/test-images/'\n",
    "CLASSES = ['pylorus', 'retroflex-stomach', 'z-line', 'other']\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Flatten \n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import skimage\n",
    "from skimage import io\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sbs\n",
    "from PIL import Image\n",
    "\n",
    "## setting the paths\n",
    "all_paths = []\n",
    "len_lis = []\n",
    "for landmark in CLASSES:\n",
    "    other_path = os.path.join(PATH, landmark, '*')\n",
    "    all_paths.append(sorted(glob.glob(other_path)))\n",
    "# all_paths = list(np.concatenate(all_paths).flat)\n",
    "\n",
    "## finding the number of image per class\n",
    "for lis in all_paths:\n",
    "    x = 0\n",
    "    for item in lis:\n",
    "        x+=1\n",
    "    print(x)\n",
    "    len_lis.append(x)\n",
    "print(len_lis)\n",
    "\n",
    "all_paths = list(np.concatenate(all_paths).flat)\n",
    "\n",
    "# df = pd.read_csv('file-names/filtered-names/numbered-labels.csv')\n",
    "# all_labels = df['Finding'].to_numpy()\n",
    "\n",
    "# # pylorus_labels = all_labels[0:5]\n",
    "# # retroflex_stomach_labels = all_labels[999:1004]\n",
    "# # zline_labels = all_labels[1763:1768]\n",
    "# # other_labels = all_labels[2695:2700]\n",
    "\n",
    "pylorus_labels = [1] * len_lis[0]\n",
    "retroflex_stomach_labels = [3] * len_lis[1]\n",
    "zline_labels = [2] * len_lis[2]\n",
    "other_labels = [0] * len_lis[3]\n",
    "all_labels = list(np.concatenate([pylorus_labels, retroflex_stomach_labels,\n",
    " zline_labels, other_labels]).flat)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in all_paths:\n",
    "# \tfile_name = path[:len(path)-4]\n",
    "# \tfile_name = file_name[:len(file_name)-4]\n",
    "# \timage = cv2.imread(path)\n",
    "# \timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# \trows, cols, dim = image.shape\n",
    "\n",
    "# \t# flipping images upside down and leftright\n",
    "# \timage_fliplr = np.fliplr(image)\n",
    "# \timage_flipud = np.flipud(image)\n",
    "# \tplt.imsave(f'{path}_image_flipud.jpg', image_flipud)\n",
    "# \tplt.imsave(f'{path}_image_fliplr.jpg', image_fliplr)\n",
    "\n",
    "# \t# rotating image\n",
    "# \trotated_img = skimage.transform.rotate(image, 90)\n",
    "# \tplt.imsave(f'{path}_rotated_img.jpg', rotated_img)\n",
    "\n",
    "# \t# shear transform on x-axis\n",
    "# \tM = np.float32([[1, 0.7, 0],\n",
    "# \t\t\t\t\t[0, 1  , 0],\n",
    "# \t\t\t\t\t[0, 0  , 1]])             \n",
    "# \tsheared_img = cv2.warpPerspective(image,M,(int(cols*1.5),int(rows*1.5)))\n",
    "# \tplt.imsave(f'{path}_sheared_img.jpg', sheared_img)\n",
    "\n",
    "# \t## zoom out\n",
    "# \tM = np.float32([[1.5, 0  , 0],\n",
    "# \t\t\t\t\t[0,   1.5, 0],\n",
    "# \t\t\t\t\t[0,   0,   1]])\n",
    "# \tscaledin_img = cv2.warpPerspective(image,M,(cols,rows))\n",
    "# \tplt.imsave(f'{path}_scaledin_img.jpg', scaledin_img)\n",
    "\n",
    "# \tM = np.float32([[0.8, 0  , 0],\n",
    "# \t\t\t\t\t[0,   0.8, 0],\n",
    "# \t\t\t\t\t[0,   0,   1]])\n",
    "# \tscaledout_img = cv2.warpPerspective(image,M,(cols,rows))\n",
    "# \tplt.imsave(f'{path}_scaledout_img.jpg', scaledout_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing pixel and label information\n",
    "new_paths = []\n",
    "count = 0\n",
    "for landmark in CLASSES:\n",
    "    other_path = os.path.join(PATH, landmark, '*')\n",
    "    new_paths.append(sorted(glob.glob(other_path)))\n",
    "    count += 1\n",
    "new_paths = list(np.concatenate(new_paths).flat)\n",
    "\n",
    "# def count_files(i):\n",
    "#     count = 0\n",
    "#     # Iterate directory\n",
    "#     for path in other_path[i]:\n",
    "#         # check if current path is a file\n",
    "#         if os.path.isfile(os.path.join(, path)):\n",
    "#             count += 1\n",
    "# print('File count:', count)\n",
    "# count_files(0)\n",
    "\n",
    "pylorus_labels = [1] * 35\n",
    "retroflex_stomach_labels = [3] * 35\n",
    "zline_labels = [2] * 35\n",
    "other_labels = [0] * 35\n",
    "all_labels = list(np.concatenate([pylorus_labels, retroflex_stomach_labels,\n",
    " zline_labels, other_labels]).flat)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "pix = []\n",
    "for path in new_paths:\n",
    "    file_name = path.split('/')[-1]\n",
    "    image = cv2.imread(path)\n",
    "    image_data = cv2.resize(image, IMAGE_SIZE, interpolation = cv2.INTER_AREA)\n",
    "    pix.append(image_data)\n",
    "\n",
    "pix = np.array(pix)\n",
    "print(len(pix))\n",
    "pix_train, pix_val, label_train, label_val = train_test_split(pix, all_labels, train_size=0.75, random_state = 42)\n",
    "label_train = keras.utils.np_utils.to_categorical(label_train, num_classes=4)\n",
    "label_val = keras.utils.np_utils.to_categorical(label_val, num_classes=4)\n",
    "print(pix_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train the existing weights\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    " \n",
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(pix_train, label_train, batch_size=5, epochs=3, validation_data=(pix_val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Plotting Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    \n",
    "    # Summarizing history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['Training Accuracy', 'Validation Accuracy'], loc='best')\n",
    "    \n",
    "    # Summarizing history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['Training Loss', 'Validation Loss'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Output Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predict = model.predict(pix_val)\n",
    "# print(label_predict)\n",
    "label_predict = np.argmax(model.predict(pix_val), axis=1)  # returns class values between 0 and 3 from highest prediction\n",
    "# print(label_predict)\n",
    "label_true = np.argmax(label_val, axis=1) \n",
    "# print(label_true)\n",
    "\n",
    "target_names = ['other (0)', 'pylorus (1)', 'z-line (2)','retroflex-stomach (3)']\n",
    "print(\"Classification report:\\n\", classification_report(label_true, label_predict, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the CNN model by creating a confusion matrix\n",
    "cm = confusion_matrix(label_true, label_predict)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot()\n",
    "\n",
    "sbs.set(font_scale=2) \n",
    "sbs.heatmap(cm, annot=True, ax=ax, cmap=\"Blues\", fmt=\"g\");  \n",
    "\n",
    "# Labels, title and ticks\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel('True Label');\n",
    "\n",
    "title_font = {'size':'36'}  \n",
    "ax.set_title('Confusion Matrix', fontdict=title_font);\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=20) \n",
    "ax.xaxis.set_ticklabels(['0', '1', '2','3']);\n",
    "ax.yaxis.set_ticklabels(['0', '1', '2','3']);\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
